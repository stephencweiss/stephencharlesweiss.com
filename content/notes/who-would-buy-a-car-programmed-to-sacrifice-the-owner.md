---
title: 'Who Would Buy A Car Programmed To Sacrifice The Owner?'
date: '2015-11-02'
publish: '2015-11-02'
category: ['musings']
tags: ['99% invisible', 'cars', 'ethics', 'qz', 'self-driving']
---

"Who would buy a car programmed to sacrifice the owner?" <sup>1</sup>

What I love about this question is that it gets at two conflicting priorities - situations in which it might make sense to kill a consumer and determining the demand for such a product.

The initial research on the subject which the article summarizes indicates that people prefer to have a car embedded with a utilitarian approach... except when they're the ones in the car (I would say they're the ones driving, but that's the point - they're no longer the drivers).

It might appear that the self-driving car is divorcing the driver from the car in the ethical decision of what when a crash is imminent. However, really what's happening is the person we normally think of as the driver is now occupying the role of the passenger while the "driver" can be thousands of miles away and is the programer who determined the car's approach to the situation. In a separate article, also on how self-driving cars make ethical decisions <sup>2</sup>, one commenter concluded, "The car should _always_ take the occupants safety as the primary goal." A summary of the argument is included and goes as follows (emphasis is my own),

> tl;dr morals: self defense is justifiable, the car represents the drivers will. Law: **walking in front of an auto makes your death your own fault.** Being tied or pushed in front of an auto makes your death the perpetrators fault. Practicality: **If people are going to actually use these cars, they need to feel safe using them.** It shouldn't be possible for someone to jump in front of your auto in order to make your car kill you.

The argument feels extreme. Even today, driver’s don’t always "take the occupants [sic] safety as the primary goal." If that were the case, we wouldn’t swerve for cats today. None-the-less, her final point seems spot on. Before addressing what self-driving cars should or shouldn't do, I wanted to see where we are today. Cars are already helping drivers identify hazards <sup>3</sup>, pedestrians they weren’t expecting <sup>4</sup>> and cars in their blind spots <sup>5</sup>. With that in mind, a discussion of ethics should be in the realms beyond these already addressed arenas. This is where our poster’s final point, comes in. Cars are already helping us detect hazards, but what happens when they are so last second that even the technology can’t stop the car, but does have the ability to affect the outcome, i.e. swerve.

Even humans, in this situation, do not respond predictably. Some will swerve in an effort to avoid the obstacle as in the case of the cat above while others will not. It is not immediately clear if those who swerve believe they will simply avoid the obstacle without risking their safety or swerve despite the increased risk to self. I would also question whether that is ever a knowable question - even for a computer. One of the underlying assumptions in the discussing the ethics of the self-driving car is that there is a knowable outcome and, working backwards, a right answer.

If there is a knowable outcome, then it seems likely a consumer would not willingly purchase a car she believed will sacrifice her for the safety of others. Even if a manufacturer attempted to be transparent, it seems unlikely that a consumer would ever get the nuanced approach used to determine the appropriate course of actions. Instead, that nuanced approach would get simplified into a soundbite and a headline - like ‘Death Panels’ of the Affordable Care Act legislation (a feature, by the way that was never included but became the focus of conversation through a misrepresentation of the law). <sup>6</sup>

Equally at fault for the failure of making such a car an attractive product for consumers is our inability to objectively asses risk. The probability of dying in a terrorist attack are infinitesimal compared to a lightning strike or in a plane compared to a car crash. <sup>7, 8</sup> It comes down to how we perceive risk vs. the actual likelihood of the risk.<sup>9</sup> Even though autonomous cars would dramatically reduce overall accidents, injuries, and car-related fatalities, because the risks are beyond our control, are in the future, and unknown, they loom large. Which brings me to whether drivers _aught_ to feel safe while driving. It seems this wasn’t always the case. A time existed when kids were encouraged to play in the streets. It was a time before cars. As the team at 99% Invisible reports in their episode, "The Modern Moloch", <sup>1</sup>⁰

> And then the automobile happened. And then automobiles began killing thousands of children, every year. Much of the public viewed the car as a death machine.
>
> One newspaper cartoon even compared the car to Moloch, the god to whom the Ammonites supposedly sacrificed their children. Pedestrian deaths were considered public tragedies. Cities held parades and built monuments in memory of children who had been struck and killed by cars. Mothers of children killed in the streets were given a special white star to honor their loss.

And later (emphasis my own),

> **If a car hit someone, the car was to blame.** From the New York Times, November 23, 1924:
>
> 'The horrors of peace appear to be appalling than the horrors of war. The automobile looms up as a far more destructive piece of mechanism than the machine gun. The reckless motorist deals more death the artilleryman. The man in streets seems less safe than the man in the trench. The greatest single lethal factor is the automobile. It left shambles in its wake as it coursed through 1923.'

| ![](https://res.cloudinary.com/scweiss1/image/upload/v1593118056/code-comments/who-would-buy-a-car-programmed-to-sacrifice-the-owner/jaywalkingwatchyourstep_plownp.jpg) |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
|                                          _Works Progress Administration/Federal Art Poster illustrated by Isadore Posoff, 1937_                                          |

But drivers couldn’t be abated and the automobile companies formed an organization, Motordom, (how’s that for an awesome name) to help transform roads into a place for cars, not people. Early attempts were unsuccessful, but when they engaged in a public ridicule campaign by re-appropriating the term jaywalker from a merely annoying pedestrian to one who crosses the street at their leisure, they hit upon a winning strategy. (Jump to 14:13 for my favorite part of the episode.)

Will the introduction of self-driving cars return to a world where the car is at fault as it was when they were first introduced, when streets were for pedestrians? Or will they remain the domain of the automobile? Of course, this is not a complete set of options and other, unknown options may yet exist. Perhaps self-driving cars will be relegated to roads underground and pedestrians will have full reign of the land. Or they only travel on specially designated roads at high speeds and don’t travel more than 10 mph in pedestrian friendly zones.

No matter what, I think the effort to get more self-driving cars on the road is the right one. They will offer so many benefits, both foreseeable and not. And as someone who no longer drives and so doesn’t need a parking spot, reducing the demand for cars and allowing that energy and space to be used for other productive purposes seems like a glorious outcome. An outcome I am excited to see.

# Footnotes

<sup>1</sup> [Why Self-Driving Cars Must Be Programmed to Kill | MIT Technology Review](http://www.technologyreview.com/view/542626/why-self-driving-cars-must-be-programmed-to-kill/) referencing "[Autonomous Vehicles Need Experimental Ethics: Are We Ready for Utilitarian Cars? | Cornell](http://arxiv.org/abs/1510.03346)
<sup>2</sup> [How to Help Self-Driving Cars Make Ethical Decisions | MIT Technology Review ](http://www.technologyreview.com/news/539731/how-to-help-self-driving-cars-make-ethical-decisions/)" and [How To Help Self Driving Cars Make Ethical Decisions | MIT Technology Review](http://www.technologyreview.com/news/539731/how-to-help-self-driving-cars-make-ethical-decisions/)
<sup>3</sup> [ATTENTION ASSIST Vehicle Safety Technology — Mercedes Benz 2013 ML-Class | YouTube](https://youtu.be/A66zgJ4Oj8o)
<sup>4</sup> [Ford and Honda stop collisions before they happen with pedestrian detection | Extreme Tech](http://www.extremetech.com/extreme/192863-ford-and-honda-stop-collisions-before-they-happen-with-pedestrian-detection)
<sup>5</sup> [Infiniti’s Blind Spot Intervention System | Infiniti USA](http://www.infinitiusa.com/now/technology/blind-spot-intervention-system.html)
<sup>6</sup> [Death Panels | Wikipedia](https://en.wikipedia.org/wiki/Death_panel)"
<sup>7</sup> [Why Terrorism Is More Frightening Than Lightning | National Review](http://www.nationalreview.com/article/398786/why-terrorism-more-frightening-lightning-charles-c-w-cooke)
<sup>8</sup> [Think air travel is risky? Try driving a car | AutoBlog](http://www.autoblog.com/2014/08/07/air-travel-safer-driving-cars-risky-feature/)
<sup>9</sup> [Perceived Risk vs. Actual Risk | Bruce Schneier](https://www.schneier.com/blog/archives/2006/11/perceived_risk_2.html)
<sup>10</sup> [The Modern Moloch | 99% Invisible](http://99percentinvisible.org/episode/episode-76-the-modern-moloch/)
<sup>11</sup> [Detects dangers before they come up](https://youtu.be/FWa-oSWGJR4)" – YouTube. While looking for information about hazard detection technology currently on the road, I found this spoof on Mercedes’ technology and detecting problems before they come up.
